# 📊 Customer Churn Prediction System

A complete end-to-end machine learning project for predicting customer churn in the IT/Telecom industry. The project includes comprehensive exploratory data analysis (EDA), multiple ML model training with hyperparameter tuning, and a production-ready FastAPI backend for serving predictions.

## 🎯 Project Overview

Customer churn prediction is critical for businesses to identify customers at risk of leaving and take proactive retention measures. This project analyzes customer data, trains multiple machine learning models, and deploys the best performing model (XGBoost) via a REST API.

**Key Highlights:**
- 📈 Comprehensive EDA with 15+ visualizations
- 🤖 Trained and compared 4 ML models
- 🏆 XGBoost achieved 93.18% ROC-AUC score
- 🚀 Production-ready FastAPI backend
- 📦 Clean, modular architecture
- 🔧 Automated feature engineering pipeline

## 📁 Project Structure

```
Project/
├── 📓 churn.ipynb                 # Complete analysis & model training notebook
├── 📋 requirements.txt            # All project dependencies
├── 📖 README.md                   # This file
│
├── 📂 data/                       # Dataset directory
│   └── IT_customer_churn.csv      # Customer data (7,043 records)
│
├── 📂 models/                     # Saved model artifacts (generated by notebook)
│   ├── xgboost_model.pkl          # Trained XGBoost model
│   ├── scaler.pkl                 # StandardScaler for normalization
│   ├── label_encoders.pkl         # Label encoders for categorical features
│   ├── feature_names.pkl          # Feature names (30 features)
│   └── model_metadata.pkl         # Model performance metrics
│
├── 📂 backend/                    # FastAPI REST API
│   ├── main.py                    # Application entry point
│   │
│   ├── 📂 api/                    # API endpoints
│   │   └── routes.py              # Route handlers
│   │
│   ├── 📂 core/                   # Core configuration
│   │   ├── config.py              # Settings & constants
│   │   └── model_loader.py        # Model management (Singleton)
│   │
│   ├── 📂 models/                 # Pydantic models
│   │   ├── request.py             # Input validation models
│   │   └── response.py            # Response models
│   │
│   ├── 📂 services/               # Business logic
│   │   ├── preprocessing.py       # Feature engineering
│   │   └── prediction.py          # Prediction service
│   │
│   ├── README.md                  # API documentation
│   └── ARCHITECTURE.md            # Architecture details
│
└── 📂 frontend/                   # Streamlit Web UI
    ├── app.py                     # Main Streamlit application
    └── README.md                  # Frontend documentation
```

## 📊 Dataset Information

- **Source**: IT/Telecom Customer Churn Dataset
- **Records**: 7,043 customers
- **Features**: 20 original features
- **Target**: Churn (Yes/No)
- **Churn Rate**: 26.54%

**Feature Categories:**
- **Demographics**: Gender, Senior Citizen, Partner, Dependents
- **Services**: Phone, Internet, Security, Backup, Streaming, etc.
- **Account**: Tenure, Contract, Payment Method, Billing
- **Charges**: Monthly Charges, Total Charges

## 🔍 Key Insights from EDA

1. **Contract Type Impact**: Month-to-month contracts have 42.71% churn vs. 2.83% for two-year contracts
2. **Tenure Effect**: Churned customers average 18 months tenure vs. 37.6 months for retained customers
3. **Internet Service**: Fiber optic customers show 41.89% churn rate vs. 18.96% for DSL
4. **High-Risk Profile**: Customers with month-to-month + electronic check payment have 53.73% churn rate
5. **Family Status**: Customers with partners/dependents have 19.82% churn vs. 34.24% without
6. **Senior Citizens**: 41.68% churn rate vs. 23.61% for non-seniors

## 🤖 Model Performance Comparison

Multiple models were trained and evaluated using Optuna for hyperparameter optimization:

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC | Training Time (s) |
|-------|----------|-----------|--------|----------|---------|-------------------|
| **XGBoost** 🏆 | **0.8541** | **0.8448** | **0.8676** | **0.8561** | **0.9318** | **15.88** |
| Gradient Boosting | 0.8556 | 0.8538 | 0.8580 | 0.8559 | 0.9304 | 738.79 |
| Random Forest | 0.8493 | 0.8289 | 0.8802 | 0.8538 | 0.9291 | 28.98 |
| Decision Tree | 0.8159 | 0.7873 | 0.8657 | 0.8247 | 0.8785 | 4.86 |

### 🏆 Best Model: XGBoost

**Why XGBoost?**
- Highest F1-Score (0.8561) - Best balance between precision and recall
- Excellent ROC-AUC (0.9318) - Superior discrimination ability
- Fast training time (15.88s) - Efficient compared to Gradient Boosting
- Robust performance across all metrics

**Optimized Hyperparameters:**
- n_estimators: 299
- learning_rate: 0.204
- max_depth: 10
- min_child_weight: 3
- subsample: 0.87
- colsample_bytree: 0.90
- gamma: 0.036

## 🛠️ Feature Engineering

The project includes sophisticated feature engineering (30 total features):

**Engineered Features:**
1. **ServiceCount**: Total number of services subscribed
2. **AvgMonthlyRate**: Average monthly rate (TotalCharges / Tenure)
3. **PremiumServiceCount**: Count of premium services
4. **HasPremiumServices**: Binary indicator for premium services
5. **HasStreaming**: Binary indicator for streaming services
6. **ValueSegment**: Customer value tier (Low/Medium/High)
7. **HighRiskProfile**: Month-to-month + Electronic check indicator
8. **FamilyCustomer**: Has partner or dependents
9. **Interaction Features**: Tenure×MonthlyCharges, Tenure×ServiceCount, MonthlyCharges×ServiceCount

## 🚀 Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train the Model

Open and run the Jupyter notebook:

```bash
jupyter notebook churn.ipynb
```

**Important**: Run all cells, especially Cell 59 which saves the model artifacts to the `models/` directory.

### 3. Start the Backend API

```bash
# Option 1: Direct execution
cd backend
python main.py

# Option 2: Using uvicorn (recommended)
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

### 4. Start the Frontend (Streamlit UI)

In a **new terminal**, run:

```bash
# From project root
streamlit run frontend/app.py
```

The web interface will open automatically at `http://localhost:8501` 🎉

### 5. Access Documentation

- **Web UI**: http://localhost:8501 (Streamlit - Beautiful interface)
- **API Swagger**: http://localhost:8000/docs (Interactive API docs)
- **API ReDoc**: http://localhost:8000/redoc (Alternative API docs)

## 🖥️ Frontend Features

The Streamlit web interface provides:

- **🏠 Home Page**: Overview, key metrics, and insights
- **🔮 Single Prediction**: Interactive form for individual predictions
- **📊 Batch Prediction**: Upload CSV for bulk predictions
- **📈 Model Info**: Performance metrics and visualizations

### Features:
- ✨ Beautiful gradient-based UI design
- 📊 Interactive Plotly visualizations
- 🎯 Probability gauges and risk indicators
- 📥 CSV template download and results export
- 🚦 Color-coded risk levels (Low/Medium/High)
- 📈 Real-time analytics and charts

## 🌐 API Endpoints

### Core Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API information and available endpoints |
| GET | `/health` | Health check and model status |
| GET | `/model/info` | Model performance metrics |
| POST | `/predict` | Single customer churn prediction |
| POST | `/predict/batch` | Batch predictions for multiple customers |

### Example Usage

#### Single Prediction

```python
import requests

url = "http://localhost:8000/predict"
customer_data = {
    "gender": "Male",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 12,
    "PhoneService": "Yes",
    "MultipleLines": "No",
    "InternetService": "Fiber optic",
    "OnlineSecurity": "No",
    "OnlineBackup": "Yes",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "Yes",
    "StreamingMovies": "Yes",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 85.50,
    "TotalCharges": 1026.00
}

response = requests.post(url, json=customer_data)
print(response.json())
```

**Response:**
```json
{
  "churn_prediction": 1,
  "churn_probability": 0.78,
  "churn_label": "Churn",
  "risk_level": "High"
}
```

#### Using cURL

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "gender": "Male",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 12,
    "PhoneService": "Yes",
    "MultipleLines": "No",
    "InternetService": "Fiber optic",
    "OnlineSecurity": "No",
    "OnlineBackup": "Yes",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "Yes",
    "StreamingMovies": "Yes",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 85.50,
    "TotalCharges": 1026.00
  }'
```

## 🎯 Risk Level Classification

The API automatically categorizes customers into risk levels:

| Risk Level | Churn Probability | Action Recommended |
|------------|-------------------|-------------------|
| 🟢 **Low** | < 30% | Standard engagement |
| 🟡 **Medium** | 30% - 60% | Proactive monitoring |
| 🔴 **High** | > 60% | Immediate intervention |

## 🏗️ Backend Architecture

The backend follows clean architecture principles with clear separation of concerns:

### Layers

1. **API Layer** (`api/`): HTTP endpoint handlers
2. **Core Layer** (`core/`): Configuration and model management
3. **Models Layer** (`models/`): Pydantic data models for validation
4. **Services Layer** (`services/`): Business logic and preprocessing

### Design Patterns

- **Singleton**: Model artifacts loaded once and shared
- **Service Pattern**: Reusable business logic components
- **Dependency Injection**: Loose coupling between layers

See `backend/ARCHITECTURE.md` for detailed architecture documentation.

## 📦 Technologies Used

### Machine Learning
- **scikit-learn**: Model training, preprocessing, evaluation
- **XGBoost**: Gradient boosting model
- **LightGBM**: Gradient boosting model
- **Optuna**: Hyperparameter optimization
- **imbalanced-learn**: SMOTE for class balancing

### Data Analysis
- **pandas**: Data manipulation
- **numpy**: Numerical computations
- **matplotlib & seaborn**: Data visualization

### Backend Development
- **FastAPI**: Modern, fast web framework
- **Pydantic**: Data validation
- **uvicorn**: ASGI server

### Frontend Development
- **Streamlit**: Web application framework
- **Plotly**: Interactive visualizations
- **requests**: API communication

## 📈 Model Training Process

1. **Data Loading**: Load and inspect raw data
2. **Data Cleaning**: Handle missing values, type conversions
3. **EDA**: Comprehensive exploratory analysis with visualizations
4. **Feature Engineering**: Create 10 new engineered features
5. **Preprocessing**: Label encoding and standardization
6. **Class Balancing**: SMOTE to handle class imbalance (26.54% churn)
7. **Train-Test Split**: 80-20 split with stratification
8. **Model Training**: Train 4 models with Optuna hyperparameter tuning
9. **Evaluation**: Compare models on multiple metrics
10. **Model Selection**: Choose XGBoost based on F1-Score
11. **Model Saving**: Export model artifacts as pickle files

## 🔧 Configuration

All backend settings are centralized in `backend/core/config.py`:

```python
# Modify these as needed
APP_TITLE = "Customer Churn Prediction API"
APP_VERSION = "1.0.0"
RISK_THRESHOLD_LOW = 0.3
RISK_THRESHOLD_MEDIUM = 0.6
```

## 📚 Documentation

- **Main README** (this file): Project overview and quick start
- **backend/README.md**: Detailed API documentation
- **backend/ARCHITECTURE.md**: Architecture and design patterns
- **Jupyter Notebook**: Complete analysis with explanations

## 🧪 Testing

Test the API endpoints using the interactive Swagger UI at `http://localhost:8000/docs` or write custom test scripts.

## 📄 License

MIT License


